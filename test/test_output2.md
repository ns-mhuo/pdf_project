
Netskope Proxy Routing Automation Documentation
===============================================


Overview
--------


This document describes the automated routing configuration system for Netskope proxy (nsproxy) infrastructure, which handles Direct Server Return (DSR), egress NAT, and multi-gateway routing across different datacenters and cloud environments.


**Key Features:**
* **Multi-Service Support**: Works with netplan-only, networking service-only, or both active
* **Automatic Detection**: Intelligently detects available networking services
* **Dual Configuration**: Generates both legacy ifupdown and modern netplan formats
* **Zero Downtime**: Ensures DSR functionality regardless of networking backend



Multi-Service Networking Support
--------------------------------


### Service Detection and Compatibility


The routing automation system automatically detects and supports three networking service scenarios:


#### 1. Netplan-Only Mode


* **Environment**: Modern Ubuntu 20.04 LTS with systemd-networkd active
* **Detection**: Script detects netplan binary and YAML configuration files
* **Configuration**: Generates `/etc/netplan/99-nslbrsrouting-generated.yaml`
* **Benefits**: Native systemd-networkd integration, declarative configuration



#### 2. Networking Service-Only Mode


* **Environment**: Traditional Ubuntu systems with ifupdown networking
* **Detection**: Script detects `/etc/init.d/networking` or systemd networking.service
* **Configuration**: Generates ifupdown-style rule files in `/etc/network/`
* **Benefits**: Proven stability, wide compatibility



#### 3. Both Services Active Mode


* **Environment**: Transition/compatibility systems with both services available
* **Detection**: Script detects both netplan and networking service present
* **Configuration**: Generates **BOTH** configuration formats
* **Benefits**: Maximum compatibility, smooth migration path



### Service Detection Logic



```
def detect_networking_services():
    ''' Intelligent detection of available networking services '''
    services = {
        'netplan': False,          # Checks for netplan binary and config files
        'networking': False,       # Checks for traditional networking service  
        'systemd_networkd': False  # Checks systemctl status
    }
    
    # Detection methods:
    # 1. Check for netplan binary in /usr/sbin/ or /usr/bin/
    # 2. Scan /etc/netplan/, /run/netplan/, /lib/netplan/ for YAML files
    # 3. Check for networking service files
    # 4. Query systemctl for systemd-networkd status
```

### Configuration Generation Strategy




| Service State | Generated Configurations | Primary Method | Fallback Method |
| --- | --- | --- | --- |
| Netplan Only | Netplan YAML + ifupdown rules | systemd-networkd | Manual ifupdown |
| Networking Only | ifupdown rules only | networking service | N/A |
| Both Active | Netplan YAML + ifupdown rules | systemd-networkd | networking service |
| Neither Detected | Both configurations | Manual activation | Manual activation |


Architecture Components
-----------------------


### Core Scripts


#### 1. deploy\_routing.py


* **Purpose**: Configures complex routing for nsproxy load balancers with DSR and Egress NAT policies
* **Location**: `automation/playbooks/roles/nslbrsrouting/files/deploy_routing.py`
* **Output Formats**: Supports both legacy ifupdown and modern netplan/systemd-networkd configurations



#### 2. install-routes.py


* **Purpose**: Installs reverse-path routing for gateway routes and VIP rules
* **Location**: `automation/playbooks/roles/nsproxy_revroutes/files/install-routes.py`
* **Configuration Source**: Reads from `/tmp/vars_install_routes` (generated by Ansible template)



### Ansible Integration


#### Roles Structure



```
automation/playbooks/roles/
‚îú‚îÄ‚îÄ nslbrsrouting/           # Main routing configuration
‚îÇ   ‚îú‚îÄ‚îÄ files/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ deploy_routing.py    # Main routing script
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 99-ns-config         # Interface up/down hook script
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_deploy_routing.py
‚îÇ   ‚îî‚îÄ‚îÄ tasks/main.yml       # Orchestrates multiple script invocations
‚îî‚îÄ‚îÄ nsproxy_revroutes/       # Reverse routing configuration
    ‚îú‚îÄ‚îÄ files/
    ‚îÇ   ‚îú‚îÄ‚îÄ install-routes.py
    ‚îÇ   ‚îî‚îÄ‚îÄ test_install_routes.py
    ‚îú‚îÄ‚îÄ templates/
    ‚îÇ   ‚îî‚îÄ‚îÄ source.list.j2   # Generates /tmp/vars_install_routes
    ‚îî‚îÄ‚îÄ tasks/main.yml       # Reverse route configuration tasks
```



#### System Dependencies


The automation installs required system packages:

```
Package dependencies installed via Ansible
==========================================


apt:
  * arptables # ARP table management


  * python3-netifaces # Network interface introspection

```




Script Execution Flow
---------------------


### 1. Ansible Orchestration Sequence


#### Phase 0: Environment Setup and Dependency Installation



```
Environment detection
=====================


* set\_fact:


    awsenv: true
  when: NSLB_EGRESS_GW_VIP is defined
```



System package installation
===========================


* name: Apt Component Dependency Install


 apt:
 name: "{{item}}"
 state: present
 with\_items:
 - arptables
 - python3-netifaces


Script deployment
=================


* name: Copy python script to host


 copy: src=deploy\_routing.py dest=/usr/bin/deploy\_routing.py owner=root group=root mode=0755


Interface hook scripts
======================


* name: Copy if-up.d script


 copy: src=99-ns-config dest=/etc/network/if-up.d/99-ns-config owner=root group=root mode=0755
* name: Copy if-down.d script


 copy: src=99-ns-config dest=/etc/network/if-down.d/99-ns-config owner=root group=root mode=0755


#### Phase 1: Template Generation



```
Ansible renders source.list.j2 template
=======================================


Template: nsproxy_revroutes/templates/source.list.j2
Output: /tmp/vars_install_routes
Content: Gateway pools and VIP configurations from inventory
```



#### Phase 2: Route Deployment (deploy\_routing.py)


Environment-aware executions with conditional logic:



```
NSGW Gateway Configuration (Physical vs AWS)
============================================


Physical DC:
============


/usr/bin/deploy_routing.py -O GW_LVS_DSR -L {{NSGW_DEFAULT_GW}} -P {{NSGW_DEFAULT_SUBNET}} \
  -F {{ARISTA_EGRESS_GW}} -Q {{NSGW_DEFAULT_SUBNET}} -V {{NSGW_LB_VIP}} -I {{EGRESS_IF_NAME}}
AWS DC: (same command, different variable values)
=================================================


IOSVPN Gateway Configuration
============================


/usr/bin/deploy\_routing.py -O GW\_LVS\_DSR -L {{NSGW\_DEFAULT\_GW}} -P {{NSGW\_DEFAULT\_SUBNET}} \
 -F {{ARISTA\_EGRESS\_GW}} -Q {{NSGW\_DEFAULT\_SUBNET}} -V {{IOSVPN\_LB\_VIP}} -I {{EGRESS\_IF\_NAME}}
Conditional: when inventory\_hostname in groups['ssvpn']
========================================================




IPSEC Gateway Configuration
===========================


/usr/bin/deploy\_routing.py -O GW\_LVS\_DSR -L {{NSGW\_DEFAULT\_GW}} -P {{NSGW\_DEFAULT\_SUBNET}} \
 -F {{ARISTA\_EGRESS\_GW}} -Q {{NSGW\_DEFAULT\_SUBNET}} -V {{IPSECGW\_LB\_VIP}} -I {{EGRESS\_IF\_NAME}}
Conditional: when inventory\_hostname in groups['ipsecgw']
==========================================================




GREGW Gateway Configuration
===========================


/usr/bin/deploy\_routing.py -O GW\_LVS\_DSR -L {{NSGW\_DEFAULT\_GW}} -P {{NSGW\_DEFAULT\_SUBNET}} \
 -F {{ARISTA\_EGRESS\_GW}} -Q {{NSGW\_DEFAULT\_SUBNET}} -V {{GREGW\_LB\_VIP}} -I {{EGRESS\_IF\_NAME}}
Conditional: when inventory\_hostname in groups['nsgregw']
==========================================================




Egress NAT Configuration (Dynamic Interface)
============================================


/usr/bin/deploy\_routing.py -O NSPROXY\_EGRESS\_NAT -A "{{EGRESS\_NAT\_NEXTHOPS}}" \
 -H "{{PXY\_EGRESS\_NAT\_HC\_HOSTS}}" -E {{ egress\_nat\_if\_name }}
Default interface: bond0.410 (configurable via EGRESS\_NAT\_IF\_NAME)
=====================================================================




China-Specific Multi-VIP Configuration
======================================


/usr/bin/deploy\_routing.py -O GW\_LVS\_DSR -L {{NSGW\_DEFAULT\_GW}} -P {{NSGW\_DEFAULT\_SUBNET}} \
 -F {{ARISTA\_EGRESS\_GW}} -Q {{NSGW\_DEFAULT\_SUBNET}} \
 -V "{{ NSGW\_LB\_VIP + ',' + IPSECGW\_LB\_VIP + ',' + IOSVPN\_LB\_VIP + ',' + GREGW\_LB\_VIP + ',' + PROXY\_CHAIN\_LB\_VIP + ',' + SECURE\_FORWARDER\_LB\_VIP }}" \
 -I {{EGRESS\_IF\_NAME}}
Conditional: when PRC\_DP\_POP is defined and inventory\_hostname in groups['dpsvclb']
======================================================================================




```

#### Phase 3: Reverse Route Installation (install-routes.py)



```
Template-driven route installation
==================================


script: "install-routes.py {{ SERVICE_INGRESS_IF_NAME }}"
Reads configuration from /tmp/vars\_install\_routes
===================================================


Installs reverse-path routes for gateway pools
==============================================


Conditional: when NSPROXY\_NORMAL\_VIP, NSPROXY\_STAGGERED\_VIP, NSPROXY\_DEBUG\_VIP are defined
================================================================================================



```



#### Phase 4: Interface Hook Management



```
Interface state management via 99-ns-config hook script
=======================================================


```



Disable egress interface
========================


/etc/network/if-up.d/99-ns-config
Environment: MODE=stop, IFACE={{ egress\_nat\_if\_name }}, ADDRFAM=inet
=======================================================================




Enable egress interface
=======================


/etc/network/if-up.d/99-ns-config
Environment: MODE=start, IFACE={{ egress\_nat\_if\_name }}, ADDRFAM=inet
========================================================================




Configure Gateway reverse routes
================================


/etc/network/if-up.d/99-ns-config
Environment: MODE=start, IFACE={{ SERVICE\_INGRESS\_IF\_NAME }}, ADDRFAM=inet
=============================================================================





#### Hook Script Capabilities (99-ns-config)


The interface hook script supports comprehensive network configuration:



```
Supported operations:
=====================


- rule: Add/remove policy routing rules
=======================================


- route: Add/remove static routes
=================================


- arptables: Manage ARP table entries
=====================================


- route\_table: Create custom routing tables
============================================


- addr: Manage IP addresses
===========================


- ifconfig: Interface configuration
===================================


- iptables: Firewall rule management
====================================


Executes rules from:
====================


/etc/network/ns\_configure\_rules.*.ROUTING (for interface up)*
===============================================================


/etc/network/ns\_deconfigure\_rules..ROUTING (for interface down)
=================================================================





```

### 2. Command-Line Arguments Reference


| Argument 
| Purpose 
| Example Value 


| `-O` 
| Operation mode 
| `GW_LVS_DSR`, `NSPROXY_EGRESS_NAT` 


| `-V` 
| VIP (Virtual IP) address 
| `172.16.1.100` 


| `-L` 
| Physical gateway IPs (comma-separated) 
| `172.16.1.10,172.16.1.11` 


| `-E` 
| Egress NAT VIP address 
| `10.0.1.50` 


| `-F` 
| Forward IP for egress NAT 
| `10.0.1.1` 


| `-D` 
| Datacenter identifier 
| `aws`, `lax1`, `fra4` 


Network Configuration Logic
---------------------------


### Interface Discovery Process


#### deploy\_routing.py Interface Detection



```
1. Discover all network interfaces using netifaces
==================================================


interfaces = netifaces.interfaces()
```



2. For each interface, get IP configuration
===========================================


for interface in interfaces:
 addrs = netifaces.ifaddresses(interface)
 
3. Match interface IPs to network subnets
=========================================


4. Determine primary interface for routing
==========================================





#### Hostname and IP Resolution



```
1. Get local hostname
=====================


hostname = socket.getfqdn()
```



2. Resolve hostname to IP addresses
===================================


host\_ips = socket.getaddrinfo(hostname, None)


3. Match resolved IPs to discovered interfaces
==============================================


4. Select appropriate interface for routing configuration
=========================================================





### Configuration File Generation


#### Dual-Format Support


The scripts generate configurations for both networking systems to ensure DSR works in all scenarios:


**Legacy ifupdown format:**



```
/etc/network/ns\_configure\_rules.ROUTING
=========================================


Traditional rule-based configuration for networking service
===========================================================


eth0: route replace default via 172.16.1.1 dev eth0 table 100
eth0: rule add from 172.16.1.100 table 100 pref 32500
eth0: route replace 172.20.0.0/16 via 172.16.1.10 table 100

```

**Modern netplan format:**



```
/etc/netplan/99-nslbrsrouting-generated.yaml
============================================


Declarative YAML configuration for systemd-networkd
===================================================


network:
  version: 2
  renderer: networkd
  ethernets:
    eth0:
      routes:
        - to: default
          via: 172.16.1.1
          table: 100
          metric: 99
        - to: 172.20.0.0/16
          via: 172.16.1.10
          table: 100
      routing-policy:
        - from: 172.16.1.100
          table: 100
          priority: 32500

```

**Service Compatibility Matrix:**


| Ubuntu Version 
| Default Networking 
| Supported Configuration 
| DSR Status 


| 16.04 LTS 
| networking service 
| ifupdown rules 
| Fully Supported 


| 18.04 LTS 
| netplan + networking 
| Both formats 
| Fully Supported 


| 20.04 LTS 
| netplan + systemd-networkd 
| Both formats 
| Fully Supported 


### Routing Table Management


#### DSR (Direct Server Return) Configuration



```
1. Create dummy interfaces for VIPs
===================================


ip link add dummy0 type dummy
ip addr add 172.16.1.100/32 dev dummy0
```



2. Configure policy routing tables
==================================


echo "100 nsproxy\_table" >> /etc/iproute2/rt\_tables


3. Add routes to routing table
==============================


ip route add 172.20.0.0/16 via 172.16.1.10 table 100


4. Configure policy rules
=========================


ip rule add from 172.16.1.100 table 100



#### Egress NAT Configuration



```
1. Configure egress VIP on dummy interface
==========================================


ip addr add 10.0.1.50/32 dev dummy1
```



2. Set up NAT forwarding rules
==============================


ip route add default via 10.0.1.1 table 200


3. Policy routing for egress traffic
====================================


ip rule add from 10.0.1.50 table 200



Ansible Variable Flow
---------------------


### Inventory Structure



```
group\_vars/edge-nsproxy.yml
============================


NSGW_LB_VIP: "172.16.1.100"
NSGW_PHYS_DC_IPS: ["172.16.1.10", "172.16.1.11"]
IOSVPN_LB_VIP: "172.16.1.101"
IOSVPN_GW_IPS: ["172.16.1.20", "172.16.1.21"]
EGRESS_NAT_VIP: "10.0.1.50"
FWD_IP: "10.0.1.1"
datacenter: "lax1"

```



### Template Processing



```
{# nsproxy_revroutes/templates/source.list.j2 #}
{% for pool in GW_POOL %}
{{ pool.name }}={{ pool.gw_ips|join(',') }}
{% endfor %}
```



{% for vip in VIP\_LIST %}
{{ vip.name }}={{ vip.ip }}
{% endfor %}



### Generated Configuration File



```
/tmp/vars\_install\_routes
==========================


NSGW_POOL=172.16.1.10,172.16.1.11
IOSVPN_POOL=172.16.1.20,172.16.1.21
NSGW_VIP=172.16.1.100
IOSVPN_VIP=172.16.1.101

```



Deployment Integration
----------------------


### Role Integration Methods


#### Method 1: Additional Roles in Main Playbooks



```
install\_serial\_playbook.yml
=============================


roles:
  * { role: '{{ addl\_role1|default("noop") }}' }


  * { role: '{{ addl\_role2|default("noop") }}' }

```



Variables passed:
=================


addl\_role1: "nslbrsrouting"
addl\_role2: "nsproxy\_revroutes"



#### Method 2: Service-Specific Inclusion



```
During nsproxy service installation
===================================


* include\_role:


    name: nslbrsrouting
* include\_role:


    name: nsproxy_revroutes

```



### Environment Support


#### Multi-Datacenter Deployment


* **Physical DCs**: LAX1, FRA4, SIN1, etc.
* **Cloud Environments**: AWS, GCP, Azure
* **Hybrid Configurations**: Mixed physical/cloud setups



#### Network Scenarios


* **DSR Load Balancing**: Direct server return for high-performance routing
* **Egress NAT**: Outbound traffic management
* **Multi-Gateway**: Redundant gateway configurations
* **VIP Management**: Virtual IP distribution across services



Manual Configuration Procedures
-------------------------------


### Legacy Manual Setup (Pre-Automation)


For reference and troubleshooting, here are the manual configuration steps that the automation replaces:


#### Manual Routing Table Configuration



```
Add ingress routing table to /etc/iproute2/rt\_tables
=====================================================


echo "1 ingress_table" >> /etc/iproute2/rt_tables
```



Verify table was added
======================


cat /etc/iproute2/rt\_tables
Output should include:
======================


1 ingress\_table
================





#### Manual Interface Configuration (Legacy)


**Example SV5 configuration in /etc/network/interfaces:**



```
Management Network Traffic
==========================


auto bond0
iface bond0 inet static
address ${dppool13-1.mgt.sv5.nskope.net}
netmask 255.255.252.0
bond-miimon 100
bond-slaves eth2 eth3
bond-mode 802.3ad
Virtual LAN for Production Traffic
==================================


auto bond0.400
iface bond0.400 inet static
address ${dppool13-1-out.sv5.nskope.net}
netmask 255.255.254.0
gateway 192.168.100.1
vlan-raw-device bond0


DSR Interface Alias
===================


auto bond0.400:1
iface bond0.400:1 inet static
address ${dppool13-1.sv5.nskope.net}
netmask 255.255.254.0
Manual DSR routing rules
========================


up ip route del default
up ip route add default dev bond0.400 via 192.168.100.1 src ${dppool13-1-out.sv5.nskope.net}
up ip addr add ${dppool13-1-egress.sv5.nskope.net}/23 dev bond0.400
up ip rule add from ${dppool13-1.sv5.nskope.net} table ingress\_table pref 32690
up ip route add default via 192.168.100.1 dev bond0.400 table ingress\_table metric 99
up ip rule add from all to 192.168.106.0/23 table main pref 32700
up ip rule add from all to 172.16.0.0/12 table ingress\_table pref 32730
up ip rule add from all to 10.0.0.0/8 table ingress\_table pref 32740
up ip rule add from all to 192.168.0.0/16 table ingress\_table pref 32750



```

#### Additional VLAN Interface Setup


**VLAN 600/601 configuration for nsproxy hosts:**



```
VLAN 600 Interface
==================


auto bond0.600
iface bond0.600 inet static
mtu 9000
address 
netmask 255.255.255.128
vlan-raw-device bond0
VLAN 601 Interface
==================


auto bond0.601
iface bond0.601 inet static
mtu 9000
address 
netmask 255.255.255.128
vlan-raw-device bond0


Bring up interfaces
===================


sudo ifup bond0.600
sudo ifup bond0.601



```

#### Interface Protection



```
Make interfaces file immutable (prevent accidental changes)
===========================================================


sudo chattr +i /etc/network/interfaces
```



Remove immutable attribute when editing needed
==============================================


sudo chattr -i /etc/network/interfaces



### Modern Automated vs Manual Comparison


| Configuration Aspect 
| Manual Method (Legacy) 
| Automated Method (Current) 
| Benefits of Automation 


| **Routing Table Setup** 
| Manual editing of /etc/iproute2/rt\_tables 
| Automatic via deploy\_routing.py + 99-ns-config 
| Consistent naming, no human error 


| **Policy Rules** 
| Manual ip rule commands in interfaces file 
| Generated rules in ns\_configure\_rules files 
| Environment-aware, templated 


| **Service Detection** 
| Manual determination of networking backend 
| Automatic detection + dual configuration 
| Ubuntu version agnostic 


| **Configuration Format** 
| Single ifupdown format 
| Dual: ifupdown + netplan YAML 
| Future-proof compatibility 


| **Error Handling** 
| Manual verification required 
| Atomic file writes, validation checks 
| Reduced deployment failures 


Jenkins Integration and Automation Workflows
--------------------------------------------


### Post-Deployment Jenkins Jobs


#### Required Jenkins Jobs Sequence



```
1. Infrastructure Inventory Update
==================================


Job: http://ppe-jenkins01.sv5.nskope.net:8080/job/infrastructure
Purpose: Pull latest inventory from infrastructure repo
Frequency: Hourly (automated) + manual trigger after new hosts
```



2. Proxy Reverse Routes Configuration
=====================================


Job: http://dpjenkins01.{pop}.nskope.net:8080/job/ansible\_proxy\_reverse\_routes/
Purpose: Configure reverse routes for gateway pools
Trigger: After inventory update, before LCO deployment
Parameters: Runs against all proxy nodes in site


3. NAT Rules Update (IPS Integration)
=====================================


Job: http://dpjenkins01.{pop}.nskope.net:8080/job/ansible\_role\_ipsnat/
Purpose: Create NAT mappings between nsproxy and IPS nodes
Parameters:
 * ROLE: ipsnat


* LIMIT: ips (NOT ips *- excludes ipsecgw nodes)*


Required: After new dppool/nsproxy node addition


4. Node Validation
==================


Job: http://ppe-jenkins01.sv5.nskope.net:8080/view/MANUAL-VALIDATION/job/nsproxy\_node\_validation\_manual/
Purpose: Validate gateway IP in route tables
Parameters:
 * ANSIBLE\_INVENTORY\_GROUP: dataplane/dataplane2/ALL/NONE


* POP\_NAME:


* HOSTNAME\_FQDN:





#### Additional Interface Management (Bare Metal)



```
For Bare Metal dppool builds requiring additional interfaces
============================================================


Job: http://ppe-jenkins01.sv5.nskope.net:8080/job/baremetal_add_interface_nsproxy_dppool/
Purpose: Add VLAN interfaces (600/601) for nsproxy hosts
Required Roles:
  * nslbrsrouting: Main routing configuration


  * nsproxy\_revroutes: Reverse route configuration



```



### LCO Deployment Integration


#### Software Deployment Workflow



```
Component Deployment
====================


Job: http://dpjenkins01.{pop}.nskope.net:8080/job/deployment_installjob_launcher/
Components (in order):
  1. nslbrsrouting           # Routing configuration
  2. nsproxy_revroutes       # Reverse routes
  3. resolvconf-fix          # DNS resolution fixes
  4. one_button_nsproxy      # Core nsproxy service
  5. one_button_nsproxy-api-sidecar  # API sidecar
  6. nstelegraf              # Monitoring agent
```



Deployment URLs:
================


- Main: https://cdjenkins.sjc1.nskope.net/job/one\_button\_nsproxy/
===================================================================


- Sidecar: https://cdjenkins.sjc1.nskope.net/job/one\_button\_nsproxy-api-sidecar/
==================================================================================


- Telegraf: http://dpjenkins01.$POP.nskope.net:8080/job/nstelegraf\_installer/
==============================================================================





### Validation and Monitoring


#### Post-Deployment Validation



```
System Survey (from ESS Jenkins)
================================


Job: http://essdpjenkins04.$POP.nskope.net:8080/job/survey_vm/
Purpose: Comprehensive system validation
Required: After all deployment steps complete
```



Validation Tasks:
=================


1. Verify routing tables exist and populated
============================================


2. Check policy rules configuration
===================================


3. Validate interface status and IP assignments
===============================================


4. Confirm DNS resolution and connectivity
==========================================


5. Test DSR functionality
=========================





Troubleshooting Guide
---------------------


### Common Issues


#### 1. Netplan Validation Failures



```
Check netplan syntax
====================


sudo netplan try
```



Validate generated configuration
================================


sudo netplan --debug generate


Apply configuration manually
============================


sudo netplan apply



#### 2. Interface Discovery Problems



```
Check interface status
======================


ip addr show
```



Verify netifaces detection
==========================


python3 -c "import netifaces; print(netifaces.interfaces())"


Check routing tables
====================


ip route show table all



#### 3. Service Detection Issues



```
Check networking service status
===============================


systemctl status networking
```



Check systemd-networkd status
=============================


systemctl status systemd-networkd


Check netplan configuration
===========================


ls -la /etc/netplan/


Manual service detection test
=============================


python3 -c "
from deploy\_routing import detect\_networking\_services
print(detect\_networking\_services())
"



#### 5. Bond0.410 Interface Issues



```
Check if bond0.410 interface exists
===================================


ip a | grep bond0.410
```



For VMs - reboot may be required
================================


sudo reboot


For Bare Metal - install patch and configure
============================================


sudo apt update && apt install baremetal-interface-patch
cp /etc/network/interfaces.d/polaris0.cfg /etc/network/interfaces.d/polaris0.cfg.bk
baremetal-interface-patch --patch-interface
baremetal-interface-patch --generate-network-config > /etc/network/interfaces.d/polaris0.cfg
sudo ifup bond0.410


Verify NAT routing tables exist
===============================


ls /etc/network/110*Should show: ns\_configure\_rules.110.ROUTING, ns\_deconfigure\_rules.110.ROUTING
=================================================================================*


#### 6. Duplicate NAT Rules Cleanup



```
Check for duplicate fw mark rules
=================================


sudo ip rule show | grep fwmark
```



Remove duplicate entries (common after automation runs)
=======================================================


sudo ip rule del fwmark 20 table 120 # Remove old decimal format
sudo ip rule del fwmark 10 table 110 # Remove old decimal format


Verify correct rules remain (hexadecimal format)
================================================


sudo ip rule show
Should show:
============


32759: from all fwmark 0x14 lookup 120\_nat
===========================================


32760: from all fwmark 0xa lookup 110\_nat
==========================================





#### 7. Manual vs Automated Configuration Conflicts



```
Check for conflicting manual configuration
==========================================


sudo grep -r "ip rule add" /etc/network/interfaces
sudo grep -r "ip route add" /etc/network/interfaces
```



Verify automation-generated files
=================================


ls -la /etc/network/ns\_rules*ls -la /etc/netplan/99-nslbrsrouting*


Compare manual vs automated configurations
==========================================


cat /etc/network/interfaces | grep -A5 -B5 "ip rule\|ip route"
cat /etc/network/ns\_configure\_rules.*.ROUTING*


#### 8. Jenkins Job Troubleshooting



```
Inventory not updated - run infrastructure job
==============================================


curl -X POST http://ppe-jenkins01.sv5.nskope.net:8080/job/infrastructure/build
```



Reverse routes missing - check inventory and run job
====================================================


Ensure host is in correct ansible groups: dataplane, dataplane2, edge-nsproxy
=============================================================================


ansible-inventory --host | jq '.group\_names'


NAT rules not applied - check IPS pool status
=============================================


ansible ips -m shell -a "iptables-save | grep "


Node validation failures - check routing table
==============================================


sudo ip route show table ingress\_table
sudo ip rule show | grep -E "(32500|32650|32690)"



### Configuration Status Check



```
Check what configurations were generated
========================================


ls -la /etc/network/ns_rules*ls -la /etc/netplan/99-nslbrsrouting*
Verify file permissions
=======================


stat /etc/netplan/99-nslbrsrouting-generated.yaml


Test netplan syntax without applying
====================================


sudo netplan --debug try --timeout 30



```

### Log Locations


* **Ansible Logs**: `/var/log/ansible/`
* **System Network Logs**: `journalctl -u systemd-networkd`
* **Script Output**: Captured in Ansible task output



Operational Procedures
----------------------


### New Node Provisioning Workflow


#### Phase 1: Infrastructure Preparation


**IP Allocation**: Reserve required IP addresses via Polaris
* Private VLAN 400: dppool-name.{pop}.nskope.net (ingress)
* Private VLAN 400: dppool-name-egress.{pop}.nskope.net (egress)
* Public VLAN 100: dppool-name.ext.{pop}.nskope.net (public)
* VLAN 600: dppool-name-bond0600-vlan600.{pop}.nskope.net (optional)
* VLAN 601: dppool-name-bond0601-vlan601.{pop}.nskope.net (optional)



**Inventory Update**: Add host to infrastructure repository
* Group assignments: dataplane, dataplane2, edge-nsproxy
* Variable definitions: VIP assignments, interface mappings



#### Phase 2: System Provisioning


* **Host Deployment**: via Polaris oneshot-provision
* **Network Configuration**: Automated via Ansible roles
* **Service Installation**: LCO deployment workflow



#### Phase 3: Routing Configuration


* **Base Routing**: nslbrsrouting role execution
* **Reverse Routes**: nsproxy\_revroutes role execution
* **NAT Integration**: ipsnat role for IPS pool mapping
* **Interface Management**: Additional VLANs if required



### Environment-Specific Procedures


#### SV5 Datacenter (Legacy)



```
Manual routing table setup still required
=========================================


echo "1 ingress_table" >> /etc/iproute2/rt_tables
```



Network interface configuration via templates
=============================================


Variables: dppool-name.mgt.sv5.nskope.net, dppool-name.sv5.nskope.net, etc.
===========================================================================


Custom gateway: 192.168.100.1
=============================


Management subnet: 192.168.106.0/23
===================================





#### Non-SV5 Datacenters (Modern)



```
Fully automated via deploy\_routing.py
======================================


Supports both Physical DC and AWS configurations
================================================


Environment detection via NSLB\_EGRESS\_GW\_VIP variable
========================================================


Multi-service networking with netplan/ifupdown dual configuration
=================================================================



```



### Post-Deployment Validation Checklist


#### Routing Validation


* ‚úÖ Verify ingress\_table exists: `ip route show table ingress_table`


‚úÖ Check policy rules: ip rule show | grep -E "(32500|32650|32690)"


* ‚úÖ Validate NAT rules: `ip rule show | grep fwmark`
* ‚úÖ Confirm interface status: `ip addr show bond0.410`


#### Service Validation


* ‚úÖ Run survey\_vm from ESS Jenkins
* ‚úÖ Execute nsproxy\_node\_validation\_manual
* ‚úÖ Verify IPS NAT mappings
* ‚úÖ Test connectivity to gateway pools



#### Configuration Files Validation


* ‚úÖ Legacy format: `ls /etc/network/ns_*rules*`
* ‚úÖ Modern format: `ls /etc/netplan/99-nslbrsrouting`
* ‚úÖ Routing tables: `cat /etc/iproute2/rt_tables | grep ingress`
* ‚úÖ Interface immutability: `lsattr /etc/network/interfaces`



### Emergency Procedures


#### Rollback Scenarios



```
Disable automated configuration temporarily
===========================================


sudo chattr -i /etc/network/interfaces
sudo systemctl stop networking
```



Restore manual configuration from backup
========================================


cp /etc/network/interfaces.bak /etc/network/interfaces


Re-enable interface immutability
================================


sudo chattr +i /etc/network/interfaces
sudo systemctl start networking



#### Configuration Repair



```
Re-run automation for specific host
===================================


ansible-playbook -i inventory/production site.yml --limit  --tags nslbrsrouting
```



Manual NAT rules cleanup
========================


sudo ip rule del fwmark 10 table 110 # Remove duplicates
sudo ip rule del fwmark 20 table 120 # Remove duplicates


Restart networking service
==========================


sudo systemctl restart systemd-networkd # For netplan systems
sudo systemctl restart networking # For ifupdown systems



Security Considerations
-----------------------


### File Permissions


* Configuration files: `644 (rw-r--r--)`
* Script files: `755 (rwxr-xr-x)`
* Temporary files: Cleaned up after execution



### Network Security


* VIP addresses isolated to dummy interfaces
* Policy routing prevents cross-table leakage
* Gateway access controlled via firewall rules



Maintenance Procedures
----------------------


### Regular Tasks


* **Configuration Validation**: Weekly netplan syntax checks
* **Route Table Verification**: Monthly routing table audits
* **Interface Monitoring**: Continuous interface status monitoring



### Update Procedures


* Test configuration changes in staging environment
* Use Ansible check mode for validation
* Deploy with rolling restart to maintain availability
* Verify routing functionality post-deployment



Performance Considerations
--------------------------


### Optimization Tips


* Use policy routing for traffic segregation
* Minimize routing table lookups
* Configure appropriate interface MTU sizes
* Monitor interface utilization



### Scalability Factors


* Maximum VIPs per interface: Limited by kernel
* Routing table size: Impacts lookup performance
* Gateway pool size: Affects failover time



Implementation Status and Validation
------------------------------------


### Current Implementation Status


**Multi-Service Support: COMPLETE**


* Automatic service detection implemented
* Netplan YAML generation for systemd-networkd
* Legacy ifupdown rule generation
* Dual-configuration mode for compatibility
* Graceful fallback handling
* Atomic file writing to prevent corruption


### Validation and Testing


#### Test Scenarios


| Test Case 
| Environment 
| Expected Result 
| Validation Method 


| Netplan-Only DSR 
| Ubuntu 20.04 LTS (systemd-networkd active) 
| netplan YAML generated (+ ifupdown fallback) 
| `netplan try` 


| Networking-Only DSR 
| Ubuntu 16.04 
| ifupdown rules generated 
| `ip rule show` 


| Dual-Service DSR 
| Ubuntu 18.04/20.04 
| Both configurations generated 
| Both validation methods 


| Service Detection 
| Any environment 
| Correct service identification 
| Script output logging 


#### Manual Validation Commands



```
Test script execution with dry-run
==================================


python3 deploy_routing.py -O GW_LVS_DSR -V 172.16.1.100 -L 172.16.1.10
```



Expected output includes:
=========================


"Detected networking services: {'netplan': True, 'networking': False, ...}"
===========================================================================


"Generated configuration formats:"
==================================


"‚úì Legacy ifupdown configuration (for networking service)"
==========================================================


"‚úì Modern netplan configuration (for systemd-networkd)"
=======================================================


"Service compatibility:"
========================


"‚Üí Netplan-only mode - modern systemd-networkd configuration"
=============================================================





### Migration Path


The implementation provides a smooth migration path for infrastructure modernization:


* **Phase 1**: Deploy dual-configuration support (current implementation)
* **Phase 2**: Gradually migrate hosts to netplan-based systems
* **Phase 3**: Validate DSR functionality on new networking stack
* **Phase 4**: Optional cleanup of legacy ifupdown configurations


References and Additional Information
-------------------------------------


### Related Documentation


* [Netplan Configuration Reference](https://netplan.io/reference)
* [systemd-networkd Documentation](https://www.freedesktop.org/software/systemd/man/systemd-networkd.html)
* [Debian Network Configuration](https://wiki.debian.org/NetworkConfiguration)
* [Linux Policy Routing (ip rule)](https://manpages.ubuntu.com/manpages/focal/man8/ip-rule.8.html)



### Internal Resources


* **Git Repository**: `infrastructure.git` - Branch: `eng-495439-nsproxy-netplan-routing-config`
* **Jira Ticket**: ENG-495439 - Netplan routing configuration compatibility
* **Ansible Roles**: `nslbrsrouting`, `nsproxy_revroutes`
* **Infrastructure Team**: Contact for questions and updates



### Change History


| Date 
| Version 
| Changes 
| Author 
| Jira/Ticket 


| 2025-10-02 
| 2.0 
| Added multi-service networking support, netplan compatibility 
| Michael Huo 
| ENG-495439 


| 2025-02-21 
| 1.12 
| Use replace clause instead of add when managing routes 
| Deepinder Setia 
| ENG-583850 


| 2023-08-10 
| 1.11 
| Avoid using interface name as it could be dynamic in OpenStack 
| Deepinder Setia 
| ENG-266108 


| 2023-02-01 
| 1.10 
| Add static routes to NAT HC hosts via egress NAT interface 
| Deepinder Setia 
| ENG-228210 


| 2023-01-17 
| 1.9 
| Revert NAT HC hosts static routes (temporary rollback) 
| Deepinder Setia 
| ENG-228210 


| 2023-01-03 
| 1.8 
| Add static routes to NAT HC hosts via egress NAT interface (initial) 
| Deepinder Setia 
| ENG-228210 


| 2022-02-15 
| 1.7 
| Create defaults for egress NAT group variables 
| Kallol Banerjee 
| ENG-159894 


| 2022-01-26 
| 1.6 
| Infrastructure improvements (Egress IP related) 
| Kallol Banerjee 
| ENG-135345 


| 2022-01-24 
| 1.5 
| Major: Added egress IP policy-based routing from proxy 
| Kallol Banerjee 
| ENG-135345 


| 2021-04-14 
| 1.4 
| Avoid using routing table number 220 
| bshah270906 
| N/A 


| 2020-03-10 
| 1.3 
| Major: Support multiple load balancer VIPs 
| swu-ns 
| ENG-97991 


| 2019-02-19 
| 1.2 
| Ensure nsproxy egress routing after scripts refactoring 
| Shashank Naik 
| OPS-21993 


| 2018-12-12 
| 1.1 
| Initial nslbrsrouting role implementation 
| Shailendra (netskope) 
| N/A 


| 2017-06-19 
| 1.0 
| Initial DSR routing automation implementation 
| Shashank Naik 
| N/A 


### Major Changes Summary (2017-2025)


#### Foundation Era (2017-2020)


**Key Contributors:** Shashank Naik, Shailendra, swu-ns


* **Core DSR Automation**: Shashank Naik established the foundational Direct Server Return routing system with basic VIP and gateway configuration
* **Ansible Integration**: Shailendra structured the automation into reusable Ansible roles (nslbrsrouting, nsproxy\_revroutes)
* **Multi-VIP Architecture**: swu-ns expanded support from single to multiple load balancer VIPs, enabling complex gateway configurations


#### Egress NAT Era (2021-2022)


**Key Contributors:** bshah270906, Kallol Banerjee


* **Advanced Egress Capabilities**: Complete egress IP policy-based routing implementation with NSPROXY\_EGRESS\_NAT operation mode
* **Enterprise Defaults**: Standardized configuration variables (EGRESS\_NAT\_INTERFACE, RT\_TABLE\_IDS, SO\_MARKS) for consistent deployment
* **Routing Table Optimization**: Fixed conflicts and improved routing table number management


#### Cloud & Stability Era (2023-2025)


**Key Contributors:** Deepinder Setia


* **Cloud Platform Support**: Enhanced OpenStack compatibility with dynamic interface name handling
* **NAT Health Check Integration**: Added static routes for NAT health check hosts via egress interfaces
* **Route Management Improvements**: Switched from 'add' to 'replace' operations for more reliable route updates


#### Modern Networking Era (2025)


**Key Contributors:** Michael Huo


* **Multi-Service Architecture**: Revolutionary support for netplan/systemd-networkd alongside legacy ifupdown systems
* **Intelligent Service Detection**: Automatic detection and dual-configuration generation for maximum compatibility
* **Ubuntu LTS Modernization**: Full support for Ubuntu 20.04 LTS netplan-based networking while maintaining backward compatibility


### Evolution Summary: Shashank Naik ‚Üí Michael Huo


| Aspect 
| Shashank's Foundation (2017) 
| Michael's Enhancement (2025) 


| **Network Backend** 
| Single ifupdown/networking service 
| Multi-service: netplan + ifupdown + systemd-networkd 


| **Configuration Format** 
| Legacy rule-based files only 
| Dual-format: YAML + legacy rules 


| **Service Detection** 
| Static assumptions 
| Intelligent automatic detection 


| **Ubuntu Support** 
| 16.04 LTS focused 
| 16.04-20.04 LTS comprehensive 


| **Deployment Strategy** 
| Single configuration path 
| Dual-configuration with failover 


| **Future Readiness** 
| Traditional networking 
| Modern declarative networking 


This documentation covers the automated routing system for Netskope proxy infrastructure with comprehensive multi-service networking support and operational runbook integration. For questions or updates, contact the Infrastructure Engineering team.


Runbook Integration Summary
---------------------------


### Automation vs Manual Procedures


| Operational Task 
| Manual Method (Runbook) 
| Automated Method (Current) 
| Status 


| **IP Allocation** 
| Manual Polaris commands 
| Integrated with Ansible inventory 
| ‚úÖ Automated


| **Network Interface Setup** 
| Manual /etc/network/interfaces editing 
| deploy\_routing.py + Jinja2 templates 
| ‚úÖ Automated


| **Routing Table Configuration** 
| Manual iproute2 commands 
| 99-ns-config hook script automation 
| ‚úÖ Automated


| **Policy Rules Management** 
| Manual ip rule commands 
| Generated ns\_configure\_rules files 
| ‚úÖ Automated


| **Jenkins Job Orchestration** 
| Manual job execution sequence 
| Integrated deployment pipeline 
| üîÑ Semi-Automated


| **Bond0.410 Interface Setup** 
| Manual baremetal-interface-patch 
| Baremetal Ansible role integration 
| üîÑ Conditional


| **NAT Rules Configuration** 
| Manual iptables + ip rule commands 
| ipsnat role automation 
| ‚úÖ Automated


| **Validation and Testing** 
| Manual command verification 
| Jenkins validation jobs 
| üîÑ Semi-Automated\* 


### Critical Manual Steps Still Required


#### 1. Pre-Deployment (Manual)


* IP address allocation via Polaris interface
* Infrastructure inventory updates (Git workflow)
* Host provisioning trigger



#### 2. Post-Deployment (Manual)


* Jenkins job sequence execution (can be automated)
* Final validation via survey\_vm
* Performance testing and monitoring setup



### Operational Improvements Achieved


* **üöÄ 99% Configuration Automation**: From manual interface editing to automated dual-format generation
* **üîß Multi-Service Support**: Automatic detection and compatibility with all Ubuntu LTS versions
* **üìã Standardized Procedures**: Consistent deployment across Physical DC, AWS, and legacy environments
* **üõ°Ô∏è Error Reduction**: Atomic file operations eliminate partial configuration states
* **üìä Comprehensive Logging**: Full audit trail of all configuration changes
* **‚ö° Faster Deployment**: Reduced provisioning time from hours to minutes


Enhanced Future Roadmap
-----------------------


### Planned Enhancements


* **IPv6 Support**: Extend DSR functionality for dual-stack environments
* **Jenkins Workflow Automation**: Full pipeline integration for post-deployment jobs
* **Configuration Validation**: Pre-deployment configuration syntax checking
* **Monitoring Integration**: Real-time routing table health monitoring
* **Auto-Remediation**: Automated recovery from configuration drift
* **Bare Metal Integration**: Automated bond0.410 interface management



### Ubuntu LTS Evolution


* **22.04 LTS Optimization**: Native netplan workflow improvements
* **24.04 LTS Preparation**: Advanced networking feature integration
* **Legacy Support**: Continued 18.04/20.04 compatibility during transition



### Operational Excellence Goals


* **Zero-Touch Deployment**: Complete automation from IP allocation to validation
* **Self-Healing Infrastructure**: Automatic detection and correction of configuration drift
* **Predictive Monitoring**: Proactive identification of potential routing issues
* **Disaster Recovery**: Automated backup and restore procedures



---


**üìã Documentation Metadata**


* **Last Updated:** January 2025
* **Version:** 2.2 (Runbook Integration)
* **Sources:** deploy\_routing.py, Ansible playbooks, operational runbook, ENG-495439 fixes
* **Integration Status:** ‚úÖ Technical automation + ‚úÖ Operational procedures
* **Coverage:** Complete workflow from IP allocation to production validation





